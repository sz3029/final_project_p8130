---
title: "Outlier VIF"
output: 
  html_document:
    toc: true
    toc_float: true
---

!! Variables that are correlated with each other don’t have a higher chance of interacting with each other in a model. Interaction means that the effect of one on the outcome will depend on the other. While correlation only means that the 2 variables tend to vary together in a linear fashion. And the latter says nothing about the effect of each on the outcome Y

Backward model:
crm_1000 ~ pop18 + docs + beds + poverty + pcincome + region + pop_density

```{r setup, include=FALSE}
library(dplyr)
library(MASS)
library(ggplot2)
library(GGally)
library(leaps)

library(performance) # vif
library(tidyverse)

library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

set.seed(1)
```

## Read in

```{r input}
crime_df = 
  read_csv("cdi.csv") %>% 
  mutate(
    region = factor(region),
    pop_density = pop / area,
    beds_density = beds / area,
    docs_density = docs / area,
    crm_1000 = 1000 * crimes / pop
  ) %>% 
  dplyr::select(-crimes, -id, -area, -pop, -beds, -docs) %>% 
  dplyr::select(crm_1000, everything()) %>%
  drop_na()
```

## Candidate Models

```{r candidate_models}
model_1 = lm(crm_1000 ~ poverty + hsgrad + beds + docs + region + pop_density + poverty*pop_density + beds*docs, data = crime_df)

# docs*region
model_2 = lm(crm_1000 ~ pop18 + docs + beds + poverty + pcincome + 
    region + pop_density + poverty*pop_density + docs*region + beds*docs, data = crime_df)

model_3 = lm(crm_1000 ~ pop18 + docs + beds + poverty + pcincome + 
    region + pop_density + poverty*pop_density + beds*docs, data = crime_df)
```

# Residuals

```{r}
plot(model_1, which = 1)
plot(model_2, which = 1)
plot(model_3, which = 1)
```

## Normal QQ plots

Filter out influential observations

```{r backward}
plot(model_1, which = 2)
plot(model_2, which = 2)
plot(model_3, which = 2)
```

The observation #11 is an outlier in all three

# Scale and locations

```{r}
plot(model_1, which = 3)
plot(model_2, which = 3)
plot(model_3, which = 3)
```
The observation #11, #215, #282 is identified

# Outliers and Leverage
```{r}
plot(model_1, which = 5)
plot(model_2, which = 5)
plot(model_3, which = 5)
```

```{r}
plot(model_1, which = 6)
plot(model_2, which = 6)
plot(model_3, which = 6)
```

The observation #6 and #1, is beyond the Cook’s distance lines of 0.5 (> 1). The plot identified the influential observation as #6, #1

```{r backward_adj}
crime_df %>%
  filter(row(crime_df) == 6 | row(crime_df) == 1)
crime_after <- crime_df %>%
  filter(row(crime_df) != 6 & row(crime_df) != 1)
```

## Colinearility

```{r}
# Correlation matrix for all variables
temp <- crime_after %>%
  dplyr::select(-state, -cty, -region)

cor(temp)
```



```{r colinear}
crime_after %>% 
  dplyr::select(-crm_1000) %>% 
  ggcorr(label = TRUE, label_size = 2, hjust = 0.8)
```

The correlation plot suggest high correlation between beds and docs, beds and totalinc, docs and totalinc. 

Let's check if the model violates colienarity

```{r}
check_collinearity(model_1)

check_collinearity(model_2)

check_collinearity(model_3)
```

```{r}
check_collinearity(model_1)

#check_collinearity(model_2_new)

check_collinearity(model_3)
```


## Final models

```{r}
model_1_new = lm(crm_1000 ~ poverty + hsgrad + beds + docs + region + pop_density + poverty*pop_density + beds*docs, data = crime_after)

# docs*region
#model_2_new = lm(crm_1000 ~ pop18 + docs + beds + poverty + pcincome + 
    #region + pop_density + poverty*pop_density + beds*docs, data = crime_after)

model_3_new = lm(crm_1000 ~ pop18 + docs + beds + poverty + pcincome + 
    region + pop_density + poverty*pop_density + beds*docs, data = crime_after)

model_1_new %>% broom::tidy() %>% knitr::kable() 
#model_2_new %>% broom::tidy() %>% knitr::kable()
model_3_new %>% broom::tidy() %>% knitr::kable()
```

```{r}
model_1 %>% broom::tidy() %>% knitr::kable()
model_2 %>% broom::tidy() %>% knitr::kable()
model_3 %>% broom::tidy() %>% knitr::kable()
```


There is no colinearity in our models



